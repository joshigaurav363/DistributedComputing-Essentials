The shuffle is Spark’s mechanism for re-distributing data so that it’s grouped differently across partitions.
This typically involves copying data across executors and machines, making the shuffle a complex and costly operation. 
shuffles generate the following costs:
Disk I/O:
  - Generates a large number of intermediate files on disk.
Network I/O:
  - Needs many network connections (Number of connections = Mapper × Reducer).
  - Because records are aggregated to new RDD partitions that might be hosted on a different Spark executor, a substantial fraction of your dataset might move between Spark executors over the network.
CPU and memory load:
  - Sorts values and merges sets of data. These operations are planned on the executor, placing a heavy load on the executor. 

What causes Shuffling:
  - Data skew: Spark shuffling may take place when some keys in a dataset are significantly more heavily populated with data than others. Data skew is the term used to describe this.
  - Operations like groupByKey, reduceByKey or same sort of joins which call for the grouping or aggregation of data by key, can also cause data shuffling.
  - Partitioning: Spark divides data among nodes through a procedure known as partitioning. The possibility of shuffling exists if the data is not distributed among partitions equally.
  - Caching : Shuffling may occur if a dataset is cached in memory and the amount of data in the cache exceeds the amount of memory on a single node.
  - Data locality: Spark tries to minimize shuffling by putting data on the same node as the computation that will be run on it. 
                   It must be moved to the node where the computation is being done if the data is not already stored there.
